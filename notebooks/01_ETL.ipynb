{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract, Transform, Load (ETL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customers Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, the customers dataset is loaded from an external source in CSV format, hosted on a GitHub repository. The data is imported using the read_csv() function from the pandas library and stored in the variable customers_df. To gain an initial understanding of the structure and contents of the dataset, the first five rows are displayed using the head() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>customer_unique_id</th>\n",
       "      <th>customer_zip_code_prefix</th>\n",
       "      <th>customer_city</th>\n",
       "      <th>customer_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>06b8999e2fba1a1fbc88172c00ba8bc7</td>\n",
       "      <td>861eff4711a542e4b93843c6dd7febb0</td>\n",
       "      <td>14409</td>\n",
       "      <td>franca</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18955e83d337fd6b2def6b18a428ac77</td>\n",
       "      <td>290c77bc529b7ac935b93aa66c333dc3</td>\n",
       "      <td>9790</td>\n",
       "      <td>sao bernardo do campo</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4e7b3e00288586ebd08712fdd0374a03</td>\n",
       "      <td>060e732b5b29e8181a18229c7b0b2b5e</td>\n",
       "      <td>1151</td>\n",
       "      <td>sao paulo</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b2b6027bc5c5109e529d4dc6358b12c3</td>\n",
       "      <td>259dac757896d24d7702b9acbbff3f3c</td>\n",
       "      <td>8775</td>\n",
       "      <td>mogi das cruzes</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4f2d8ab171c80ec8364f7c12e35b23ad</td>\n",
       "      <td>345ecd01c38d18a9036ed96c73b8d066</td>\n",
       "      <td>13056</td>\n",
       "      <td>campinas</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        customer_id                customer_unique_id  \\\n",
       "0  06b8999e2fba1a1fbc88172c00ba8bc7  861eff4711a542e4b93843c6dd7febb0   \n",
       "1  18955e83d337fd6b2def6b18a428ac77  290c77bc529b7ac935b93aa66c333dc3   \n",
       "2  4e7b3e00288586ebd08712fdd0374a03  060e732b5b29e8181a18229c7b0b2b5e   \n",
       "3  b2b6027bc5c5109e529d4dc6358b12c3  259dac757896d24d7702b9acbbff3f3c   \n",
       "4  4f2d8ab171c80ec8364f7c12e35b23ad  345ecd01c38d18a9036ed96c73b8d066   \n",
       "\n",
       "   customer_zip_code_prefix          customer_city customer_state  \n",
       "0                     14409                 franca             SP  \n",
       "1                      9790  sao bernardo do campo             SP  \n",
       "2                      1151              sao paulo             SP  \n",
       "3                      8775        mogi das cruzes             SP  \n",
       "4                     13056               campinas             SP  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customers_url = \"https://raw.githubusercontent.com/aryashidika/Brazilian-Store-Analysis/refs/heads/main/data/raw/olist_customers_dataset.csv\"\n",
    "customers_df = pd.read_csv(customers_url)\n",
    "customers_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The info() method is used to display a concise summary of the DataFrame. It provides important information such as the number of entries, column names, data types, and the number of non-null values in each column. This helps to quickly assess the completeness of the data and identify potential missing values or data type issues that may need to be addressed during preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 99441 entries, 0 to 99440\n",
      "Data columns (total 5 columns):\n",
      " #   Column                    Non-Null Count  Dtype \n",
      "---  ------                    --------------  ----- \n",
      " 0   customer_id               99441 non-null  object\n",
      " 1   customer_unique_id        99441 non-null  object\n",
      " 2   customer_zip_code_prefix  99441 non-null  int64 \n",
      " 3   customer_city             99441 non-null  object\n",
      " 4   customer_state            99441 non-null  object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 3.8+ MB\n"
     ]
    }
   ],
   "source": [
    "customers_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that there are no columns with null or missing values, and the data types are appropriate.\n",
    "\n",
    "The next line checks for duplicate entries in the customer_id column of the customers_df DataFrame. It returns the total number of duplicate customer IDs, helping to ensure data uniqueness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customers_df.duplicated(subset=['customer_id']).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This block of code removes leading and trailing whitespace characters from key text columns in the customers_df DataFrame: customer_id, customer_unique_id, customer_city, and customer_state. This is done using the apply() function with a lambda expression, ensuring consistent formatting and preventing potential issues during analysis or merging operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers_df['customer_id'] = customers_df['customer_id'].apply(lambda x: str(x).strip())\n",
    "customers_df['customer_unique_id'] = customers_df['customer_unique_id'].apply(lambda x: str(x).strip())\n",
    "customers_df['customer_city'] = customers_df['customer_city'].apply(lambda x: str(x).strip())\n",
    "customers_df['customer_state'] = customers_df['customer_state'].apply(lambda x: str(x).strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Orders Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next data will also be loaded using the pandas library and stored in the variable orders_df, with the first five rows displayed to gain an initial understanding of the structure and contents of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>order_status</th>\n",
       "      <th>order_purchase_timestamp</th>\n",
       "      <th>order_approved_at</th>\n",
       "      <th>order_delivered_carrier_date</th>\n",
       "      <th>order_delivered_customer_date</th>\n",
       "      <th>order_estimated_delivery_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e481f51cbdc54678b7cc49136f2d6af7</td>\n",
       "      <td>9ef432eb6251297304e76186b10a928d</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2017-10-02 10:56:33</td>\n",
       "      <td>2017-10-02 11:07:15</td>\n",
       "      <td>2017-10-04 19:55:00</td>\n",
       "      <td>2017-10-10 21:25:13</td>\n",
       "      <td>2017-10-18 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53cdb2fc8bc7dce0b6741e2150273451</td>\n",
       "      <td>b0830fb4747a6c6d20dea0b8c802d7ef</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2018-07-24 20:41:37</td>\n",
       "      <td>2018-07-26 03:24:27</td>\n",
       "      <td>2018-07-26 14:31:00</td>\n",
       "      <td>2018-08-07 15:27:45</td>\n",
       "      <td>2018-08-13 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47770eb9100c2d0c44946d9cf07ec65d</td>\n",
       "      <td>41ce2a54c0b03bf3443c3d931a367089</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2018-08-08 08:38:49</td>\n",
       "      <td>2018-08-08 08:55:23</td>\n",
       "      <td>2018-08-08 13:50:00</td>\n",
       "      <td>2018-08-17 18:06:29</td>\n",
       "      <td>2018-09-04 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>949d5b44dbf5de918fe9c16f97b45f8a</td>\n",
       "      <td>f88197465ea7920adcdbec7375364d82</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2017-11-18 19:28:06</td>\n",
       "      <td>2017-11-18 19:45:59</td>\n",
       "      <td>2017-11-22 13:39:59</td>\n",
       "      <td>2017-12-02 00:28:42</td>\n",
       "      <td>2017-12-15 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ad21c59c0840e6cb83a9ceb5573f8159</td>\n",
       "      <td>8ab97904e6daea8866dbdbc4fb7aad2c</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2018-02-13 21:18:39</td>\n",
       "      <td>2018-02-13 22:20:29</td>\n",
       "      <td>2018-02-14 19:46:34</td>\n",
       "      <td>2018-02-16 18:17:02</td>\n",
       "      <td>2018-02-26 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           order_id                       customer_id  \\\n",
       "0  e481f51cbdc54678b7cc49136f2d6af7  9ef432eb6251297304e76186b10a928d   \n",
       "1  53cdb2fc8bc7dce0b6741e2150273451  b0830fb4747a6c6d20dea0b8c802d7ef   \n",
       "2  47770eb9100c2d0c44946d9cf07ec65d  41ce2a54c0b03bf3443c3d931a367089   \n",
       "3  949d5b44dbf5de918fe9c16f97b45f8a  f88197465ea7920adcdbec7375364d82   \n",
       "4  ad21c59c0840e6cb83a9ceb5573f8159  8ab97904e6daea8866dbdbc4fb7aad2c   \n",
       "\n",
       "  order_status order_purchase_timestamp    order_approved_at  \\\n",
       "0    delivered      2017-10-02 10:56:33  2017-10-02 11:07:15   \n",
       "1    delivered      2018-07-24 20:41:37  2018-07-26 03:24:27   \n",
       "2    delivered      2018-08-08 08:38:49  2018-08-08 08:55:23   \n",
       "3    delivered      2017-11-18 19:28:06  2017-11-18 19:45:59   \n",
       "4    delivered      2018-02-13 21:18:39  2018-02-13 22:20:29   \n",
       "\n",
       "  order_delivered_carrier_date order_delivered_customer_date  \\\n",
       "0          2017-10-04 19:55:00           2017-10-10 21:25:13   \n",
       "1          2018-07-26 14:31:00           2018-08-07 15:27:45   \n",
       "2          2018-08-08 13:50:00           2018-08-17 18:06:29   \n",
       "3          2017-11-22 13:39:59           2017-12-02 00:28:42   \n",
       "4          2018-02-14 19:46:34           2018-02-16 18:17:02   \n",
       "\n",
       "  order_estimated_delivery_date  \n",
       "0           2017-10-18 00:00:00  \n",
       "1           2018-08-13 00:00:00  \n",
       "2           2018-09-04 00:00:00  \n",
       "3           2017-12-15 00:00:00  \n",
       "4           2018-02-26 00:00:00  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orders_url = \"https://raw.githubusercontent.com/aryashidika/Brazilian-Store-Analysis/refs/heads/main/data/raw/olist_orders_dataset.csv\"\n",
    "orders_df = pd.read_csv(orders_url)\n",
    "orders_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following line removes the 'order_approved_at' and 'order_delivered_carrier_date' columns from the orders_df DataFrame. These columns are excluded as they are not required for the subsequent analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_df = orders_df.drop(columns=['order_approved_at', 'order_delivered_carrier_date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step will examine the summary of the data using info(), which provides information on missing values and data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 99441 entries, 0 to 99440\n",
      "Data columns (total 6 columns):\n",
      " #   Column                         Non-Null Count  Dtype \n",
      "---  ------                         --------------  ----- \n",
      " 0   order_id                       99441 non-null  object\n",
      " 1   customer_id                    99441 non-null  object\n",
      " 2   order_status                   99441 non-null  object\n",
      " 3   order_purchase_timestamp       99441 non-null  object\n",
      " 4   order_delivered_customer_date  96476 non-null  object\n",
      " 5   order_estimated_delivery_date  99441 non-null  object\n",
      "dtypes: object(6)\n",
      "memory usage: 4.6+ MB\n"
     ]
    }
   ],
   "source": [
    "orders_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the summary above, it is observed that the order_delivered_customer_date column contains some null values, and several other columns do not have the correct data types.\n",
    "\n",
    "Next, we will examine how many duplicates exist in the data, specifically in the customer_id and order_id columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(orders_df.duplicated(subset=['customer_id']).sum())\n",
    "print(orders_df.duplicated(subset=['order_id']).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code will check how many null values are present in each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "order_id                            0\n",
       "customer_id                         0\n",
       "order_status                        0\n",
       "order_purchase_timestamp            0\n",
       "order_delivered_customer_date    2965\n",
       "order_estimated_delivery_date       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orders_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The order_delivered_customer_date column contains 2,965 missing values. Further investigation will be conducted by examining the order_status to understand the context of these missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order_status\n",
      "shipped        1107\n",
      "canceled        619\n",
      "unavailable     609\n",
      "invoiced        314\n",
      "processing      301\n",
      "delivered         8\n",
      "created           5\n",
      "approved          2\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(orders_df[orders_df['order_delivered_customer_date'].isna()]['order_status'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code will identify orders with a status of 'delivered' but without a delivery date. These orders will then be removed from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_df = orders_df[~((orders_df['order_status'] == 'delivered') & (orders_df['order_delivered_customer_date'].isna()))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following line of code checks whether there are any records with a non-null delivery date (order_delivered_customer_date) but a status that is not marked as \"delivered\". This helps identify potential inconsistencies in the delivery information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['canceled'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "invalid_rows = orders_df.loc[(orders_df['order_status'] != 'delivered') & orders_df['order_delivered_customer_date'].notna()]\n",
    "invalid_rows['order_status'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After identifying the status of the invalid rows, the next step is to remove them from the dataset. Dan semua yang memiliki missing value di kolom 'order_delivered_customer_date' dibiarkan karena sudah sesuai tidak mempunyai tanggal delivered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_df = orders_df[~((orders_df['order_status'] == 'canceled') & orders_df['order_delivered_customer_date'].notna())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following lines convert the order_purchase_timestamp, order_delivered_customer_date, and order_estimated_delivery_date columns to datetime format using pd.to_datetime(). This ensures that the date-related data can be properly interpreted and analyzed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_df['order_purchase_timestamp'] = pd.to_datetime(orders_df['order_purchase_timestamp'])\n",
    "orders_df['order_delivered_customer_date'] = pd.to_datetime(orders_df['order_delivered_customer_date'])\n",
    "orders_df['order_estimated_delivery_date'] = pd.to_datetime(orders_df['order_estimated_delivery_date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following lines apply string cleaning to the order_id, customer_id, and order_status columns. Each value is converted to a string and stripped of leading and trailing whitespace using the strip() method. This step helps ensure consistency in textual data for accurate analysis and merging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_df['order_id'] = orders_df['order_id'].apply(lambda x: str(x).strip())\n",
    "orders_df['customer_id'] = orders_df['customer_id'].apply(lambda x: str(x).strip())\n",
    "orders_df['order_status'] = orders_df['order_status'].apply(lambda x: str(x).strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Order Items Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next data will also be loaded using the pandas library and stored in the variable order_items_df, with the first five rows displayed to gain an initial understanding of the structure and contents of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>order_item_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>seller_id</th>\n",
       "      <th>shipping_limit_date</th>\n",
       "      <th>price</th>\n",
       "      <th>freight_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00010242fe8c5a6d1ba2dd792cb16214</td>\n",
       "      <td>1</td>\n",
       "      <td>4244733e06e7ecb4970a6e2683c13e61</td>\n",
       "      <td>48436dade18ac8b2bce089ec2a041202</td>\n",
       "      <td>2017-09-19 09:45:35</td>\n",
       "      <td>58.90</td>\n",
       "      <td>13.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00018f77f2f0320c557190d7a144bdd3</td>\n",
       "      <td>1</td>\n",
       "      <td>e5f2d52b802189ee658865ca93d83a8f</td>\n",
       "      <td>dd7ddc04e1b6c2c614352b383efe2d36</td>\n",
       "      <td>2017-05-03 11:05:13</td>\n",
       "      <td>239.90</td>\n",
       "      <td>19.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000229ec398224ef6ca0657da4fc703e</td>\n",
       "      <td>1</td>\n",
       "      <td>c777355d18b72b67abbeef9df44fd0fd</td>\n",
       "      <td>5b51032eddd242adc84c38acab88f23d</td>\n",
       "      <td>2018-01-18 14:48:30</td>\n",
       "      <td>199.00</td>\n",
       "      <td>17.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00024acbcdf0a6daa1e931b038114c75</td>\n",
       "      <td>1</td>\n",
       "      <td>7634da152a4610f1595efa32f14722fc</td>\n",
       "      <td>9d7a1d34a5052409006425275ba1c2b4</td>\n",
       "      <td>2018-08-15 10:10:18</td>\n",
       "      <td>12.99</td>\n",
       "      <td>12.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00042b26cf59d7ce69dfabb4e55b4fd9</td>\n",
       "      <td>1</td>\n",
       "      <td>ac6c3623068f30de03045865e4e10089</td>\n",
       "      <td>df560393f3a51e74553ab94004ba5c87</td>\n",
       "      <td>2017-02-13 13:57:51</td>\n",
       "      <td>199.90</td>\n",
       "      <td>18.14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           order_id  order_item_id  \\\n",
       "0  00010242fe8c5a6d1ba2dd792cb16214              1   \n",
       "1  00018f77f2f0320c557190d7a144bdd3              1   \n",
       "2  000229ec398224ef6ca0657da4fc703e              1   \n",
       "3  00024acbcdf0a6daa1e931b038114c75              1   \n",
       "4  00042b26cf59d7ce69dfabb4e55b4fd9              1   \n",
       "\n",
       "                         product_id                         seller_id  \\\n",
       "0  4244733e06e7ecb4970a6e2683c13e61  48436dade18ac8b2bce089ec2a041202   \n",
       "1  e5f2d52b802189ee658865ca93d83a8f  dd7ddc04e1b6c2c614352b383efe2d36   \n",
       "2  c777355d18b72b67abbeef9df44fd0fd  5b51032eddd242adc84c38acab88f23d   \n",
       "3  7634da152a4610f1595efa32f14722fc  9d7a1d34a5052409006425275ba1c2b4   \n",
       "4  ac6c3623068f30de03045865e4e10089  df560393f3a51e74553ab94004ba5c87   \n",
       "\n",
       "   shipping_limit_date   price  freight_value  \n",
       "0  2017-09-19 09:45:35   58.90          13.29  \n",
       "1  2017-05-03 11:05:13  239.90          19.93  \n",
       "2  2018-01-18 14:48:30  199.00          17.87  \n",
       "3  2018-08-15 10:10:18   12.99          12.79  \n",
       "4  2017-02-13 13:57:51  199.90          18.14  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order_items_url = \"https://raw.githubusercontent.com/aryashidika/Brazilian-Store-Analysis/refs/heads/main/data/raw/olist_order_items_dataset.csv\"\n",
    "order_items_df = pd.read_csv(order_items_url)\n",
    "order_items_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following line removes the 'seller_id' and 'shipping_limit_date' columns from the order_items_df DataFrame. These columns are excluded as they are not required for the subsequent analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_items_df = order_items_df.drop(columns=['seller_id', 'shipping_limit_date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step will examine the summary of the data using info(), which provides information on missing values and data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 112650 entries, 0 to 112649\n",
      "Data columns (total 5 columns):\n",
      " #   Column         Non-Null Count   Dtype  \n",
      "---  ------         --------------   -----  \n",
      " 0   order_id       112650 non-null  object \n",
      " 1   order_item_id  112650 non-null  int64  \n",
      " 2   product_id     112650 non-null  object \n",
      " 3   price          112650 non-null  float64\n",
      " 4   freight_value  112650 non-null  float64\n",
      "dtypes: float64(2), int64(1), object(2)\n",
      "memory usage: 4.3+ MB\n"
     ]
    }
   ],
   "source": [
    "order_items_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be observed that the dataset does not contain any null values.\n",
    "\n",
    "Next, the number of duplicate values in the 'order_id' column and duplicate rows in the dataset will be examined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicated order_id:  13984\n",
      "Duplicated rows:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Duplicated order_id: \", order_items_df.duplicated(subset=['order_id']).sum())\n",
    "print(\"Duplicated rows: \", order_items_df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The order_id column contains 13,984 duplicate entries. The next step is to examine the structure of the rows with duplicated order_id values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>order_item_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>price</th>\n",
       "      <th>freight_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0008288aa423d2a3f00fcb17cd7d8719</td>\n",
       "      <td>1</td>\n",
       "      <td>368c6c730842d78016ad823897a372db</td>\n",
       "      <td>49.90</td>\n",
       "      <td>13.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0008288aa423d2a3f00fcb17cd7d8719</td>\n",
       "      <td>2</td>\n",
       "      <td>368c6c730842d78016ad823897a372db</td>\n",
       "      <td>49.90</td>\n",
       "      <td>13.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>00143d0f86d6fbd9f9b38ab440ac16f5</td>\n",
       "      <td>1</td>\n",
       "      <td>e95ee6822b66ac6058e2e4aff656071a</td>\n",
       "      <td>21.33</td>\n",
       "      <td>15.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>00143d0f86d6fbd9f9b38ab440ac16f5</td>\n",
       "      <td>2</td>\n",
       "      <td>e95ee6822b66ac6058e2e4aff656071a</td>\n",
       "      <td>21.33</td>\n",
       "      <td>15.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>00143d0f86d6fbd9f9b38ab440ac16f5</td>\n",
       "      <td>3</td>\n",
       "      <td>e95ee6822b66ac6058e2e4aff656071a</td>\n",
       "      <td>21.33</td>\n",
       "      <td>15.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>001ab0a7578dd66cd4b0a71f5b6e1e41</td>\n",
       "      <td>1</td>\n",
       "      <td>0b0172eb0fd18479d29c3bc122c058c2</td>\n",
       "      <td>24.89</td>\n",
       "      <td>17.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>001ab0a7578dd66cd4b0a71f5b6e1e41</td>\n",
       "      <td>2</td>\n",
       "      <td>0b0172eb0fd18479d29c3bc122c058c2</td>\n",
       "      <td>24.89</td>\n",
       "      <td>17.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>001ab0a7578dd66cd4b0a71f5b6e1e41</td>\n",
       "      <td>3</td>\n",
       "      <td>0b0172eb0fd18479d29c3bc122c058c2</td>\n",
       "      <td>24.89</td>\n",
       "      <td>17.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>001d8f0e34a38c37f7dba2a37d4eba8b</td>\n",
       "      <td>1</td>\n",
       "      <td>e67307ff0f15ade43fcb6e670be7a74c</td>\n",
       "      <td>18.99</td>\n",
       "      <td>7.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>001d8f0e34a38c37f7dba2a37d4eba8b</td>\n",
       "      <td>2</td>\n",
       "      <td>e67307ff0f15ade43fcb6e670be7a74c</td>\n",
       "      <td>18.99</td>\n",
       "      <td>7.78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            order_id  order_item_id  \\\n",
       "13  0008288aa423d2a3f00fcb17cd7d8719              1   \n",
       "14  0008288aa423d2a3f00fcb17cd7d8719              2   \n",
       "32  00143d0f86d6fbd9f9b38ab440ac16f5              1   \n",
       "33  00143d0f86d6fbd9f9b38ab440ac16f5              2   \n",
       "34  00143d0f86d6fbd9f9b38ab440ac16f5              3   \n",
       "42  001ab0a7578dd66cd4b0a71f5b6e1e41              1   \n",
       "43  001ab0a7578dd66cd4b0a71f5b6e1e41              2   \n",
       "44  001ab0a7578dd66cd4b0a71f5b6e1e41              3   \n",
       "48  001d8f0e34a38c37f7dba2a37d4eba8b              1   \n",
       "49  001d8f0e34a38c37f7dba2a37d4eba8b              2   \n",
       "\n",
       "                          product_id  price  freight_value  \n",
       "13  368c6c730842d78016ad823897a372db  49.90          13.37  \n",
       "14  368c6c730842d78016ad823897a372db  49.90          13.37  \n",
       "32  e95ee6822b66ac6058e2e4aff656071a  21.33          15.10  \n",
       "33  e95ee6822b66ac6058e2e4aff656071a  21.33          15.10  \n",
       "34  e95ee6822b66ac6058e2e4aff656071a  21.33          15.10  \n",
       "42  0b0172eb0fd18479d29c3bc122c058c2  24.89          17.63  \n",
       "43  0b0172eb0fd18479d29c3bc122c058c2  24.89          17.63  \n",
       "44  0b0172eb0fd18479d29c3bc122c058c2  24.89          17.63  \n",
       "48  e67307ff0f15ade43fcb6e670be7a74c  18.99           7.78  \n",
       "49  e67307ff0f15ade43fcb6e670be7a74c  18.99           7.78  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_duplicates = order_items_df[order_items_df.duplicated(subset=['order_id'], keep=False)]\n",
    "df_duplicates.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As observed from the table, the order_id values appear duplicated because some orders include more than one product. Each product purchased within the same order is listed separately, as indicated by the order_item_id column.\n",
    "\n",
    "The following lines apply the strip() method to the order_id and product_id columns of the order_items_df DataFrame. This ensures that any leading or trailing spaces in the values are removed, and the values are converted to strings using str() for consistent formatting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_items_df['order_id'] = order_items_df['order_id'].apply(lambda x: str(x).strip())\n",
    "order_items_df['product_id'] = order_items_df['product_id'].apply(lambda x: str(x).strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Products Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next data will also be loaded using the pandas library and stored in the variable products_df, with the first five rows displayed to gain an initial understanding of the structure and contents of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_category_name</th>\n",
       "      <th>product_name_lenght</th>\n",
       "      <th>product_description_lenght</th>\n",
       "      <th>product_photos_qty</th>\n",
       "      <th>product_weight_g</th>\n",
       "      <th>product_length_cm</th>\n",
       "      <th>product_height_cm</th>\n",
       "      <th>product_width_cm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32946</th>\n",
       "      <td>a0b7d5a992ccda646f2d34e418fff5a0</td>\n",
       "      <td>moveis_decoracao</td>\n",
       "      <td>45.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12300.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32947</th>\n",
       "      <td>bf4538d88321d0fd4412a93c974510e6</td>\n",
       "      <td>construcao_ferramentas_iluminacao</td>\n",
       "      <td>41.0</td>\n",
       "      <td>971.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32948</th>\n",
       "      <td>9a7c6041fa9592d9d9ef6cfe62a71f8c</td>\n",
       "      <td>cama_mesa_banho</td>\n",
       "      <td>50.0</td>\n",
       "      <td>799.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1400.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32949</th>\n",
       "      <td>83808703fc0706a22e264b9d75f04a2e</td>\n",
       "      <td>informatica_acessorios</td>\n",
       "      <td>60.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>700.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32950</th>\n",
       "      <td>106392145fca363410d287a815be6de4</td>\n",
       "      <td>cama_mesa_banho</td>\n",
       "      <td>58.0</td>\n",
       "      <td>309.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2083.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             product_id              product_category_name  \\\n",
       "32946  a0b7d5a992ccda646f2d34e418fff5a0                   moveis_decoracao   \n",
       "32947  bf4538d88321d0fd4412a93c974510e6  construcao_ferramentas_iluminacao   \n",
       "32948  9a7c6041fa9592d9d9ef6cfe62a71f8c                    cama_mesa_banho   \n",
       "32949  83808703fc0706a22e264b9d75f04a2e             informatica_acessorios   \n",
       "32950  106392145fca363410d287a815be6de4                    cama_mesa_banho   \n",
       "\n",
       "       product_name_lenght  product_description_lenght  product_photos_qty  \\\n",
       "32946                 45.0                        67.0                 2.0   \n",
       "32947                 41.0                       971.0                 1.0   \n",
       "32948                 50.0                       799.0                 1.0   \n",
       "32949                 60.0                       156.0                 2.0   \n",
       "32950                 58.0                       309.0                 1.0   \n",
       "\n",
       "       product_weight_g  product_length_cm  product_height_cm  \\\n",
       "32946           12300.0               40.0               40.0   \n",
       "32947            1700.0               16.0               19.0   \n",
       "32948            1400.0               27.0                7.0   \n",
       "32949             700.0               31.0               13.0   \n",
       "32950            2083.0               12.0                2.0   \n",
       "\n",
       "       product_width_cm  \n",
       "32946              40.0  \n",
       "32947              16.0  \n",
       "32948              27.0  \n",
       "32949              20.0  \n",
       "32950               7.0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products_url = \"https://raw.githubusercontent.com/aryashidika/Brazilian-Store-Analysis/refs/heads/main/data/raw/olist_products_dataset.csv\"\n",
    "products_df = pd.read_csv(products_url)\n",
    "products_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following line removes the 'product_name_lenght', 'product_description_lenght', 'product_photos_qty', 'product_length_cm', 'product_height_cm', and 'product_width_cm' columns from the products_df DataFrame. These columns are excluded as they are not required for the subsequent analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "products_df = products_df.drop(columns=['product_weight_g','product_name_lenght', 'product_description_lenght', 'product_photos_qty', 'product_length_cm', 'product_height_cm', 'product_width_cm'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step will examine the summary of the data using info(), which provides information on missing values and data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32951 entries, 0 to 32950\n",
      "Data columns (total 2 columns):\n",
      " #   Column                 Non-Null Count  Dtype \n",
      "---  ------                 --------------  ----- \n",
      " 0   product_id             32951 non-null  object\n",
      " 1   product_category_name  32341 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 515.0+ KB\n"
     ]
    }
   ],
   "source": [
    "products_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the summary above, it is observed that the 'product_category_name' column contains some null values, and several other columns do not have the correct data types.\n",
    "\n",
    "Next, we will examine how many duplicates exist in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicated rows:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Duplicated rows: \", products_df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicated product id:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Duplicated product id: \", products_df.duplicated(subset=['product_id']).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to check the number of missing values in each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "product_id                 0\n",
       "product_category_name    610\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 610 missing values in the product_category_name column. These missing values will be replaced with the value \"Unknown\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "products_df['product_category_name'].fillna(\"Unknown\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following lines of code remove any leading or trailing whitespace from the product_id and product_category_name columns in the products_df DataFrame. The apply() function is used with a lambda function that converts each value to a string and applies the strip() method to eliminate any extra spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "products_df['product_id'] = products_df['product_id'].apply(lambda x: str(x).strip())\n",
    "products_df['product_category_name'] = products_df['product_category_name'].apply(lambda x: str(x).strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geolocation Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next data will also be loaded using the pandas library and stored in the variable geolocation_df, with the first five rows displayed to gain an initial understanding of the structure and contents of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geolocation_zip_code_prefix</th>\n",
       "      <th>geolocation_lat</th>\n",
       "      <th>geolocation_lng</th>\n",
       "      <th>geolocation_city</th>\n",
       "      <th>geolocation_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1037</td>\n",
       "      <td>-23.545621</td>\n",
       "      <td>-46.639292</td>\n",
       "      <td>sao paulo</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1046</td>\n",
       "      <td>-23.546081</td>\n",
       "      <td>-46.644820</td>\n",
       "      <td>sao paulo</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1046</td>\n",
       "      <td>-23.546129</td>\n",
       "      <td>-46.642951</td>\n",
       "      <td>sao paulo</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1041</td>\n",
       "      <td>-23.544392</td>\n",
       "      <td>-46.639499</td>\n",
       "      <td>sao paulo</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1035</td>\n",
       "      <td>-23.541578</td>\n",
       "      <td>-46.641607</td>\n",
       "      <td>sao paulo</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   geolocation_zip_code_prefix  geolocation_lat  geolocation_lng  \\\n",
       "0                         1037       -23.545621       -46.639292   \n",
       "1                         1046       -23.546081       -46.644820   \n",
       "2                         1046       -23.546129       -46.642951   \n",
       "3                         1041       -23.544392       -46.639499   \n",
       "4                         1035       -23.541578       -46.641607   \n",
       "\n",
       "  geolocation_city geolocation_state  \n",
       "0        sao paulo                SP  \n",
       "1        sao paulo                SP  \n",
       "2        sao paulo                SP  \n",
       "3        sao paulo                SP  \n",
       "4        sao paulo                SP  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geolocation_url = \"https://raw.githubusercontent.com/aryashidika/Brazilian-Store-Analysis/refs/heads/main/data/raw/olist_geolocation_dataset.csv\"\n",
    "geolocation_df = pd.read_csv(geolocation_url)\n",
    "geolocation_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following line removes the 'geolocation_city', 'geolocation_lat', and 'geolocation_lng' columns from the orders_df DataFrame. These columns are excluded as they are not required for the subsequent analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "geolocation_df = geolocation_df.drop(columns=['geolocation_city','geolocation_lat','geolocation_lng'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step will examine the summary of the data using info(), which provides information on missing values and data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000163 entries, 0 to 1000162\n",
      "Data columns (total 2 columns):\n",
      " #   Column                       Non-Null Count    Dtype \n",
      "---  ------                       --------------    ----- \n",
      " 0   geolocation_zip_code_prefix  1000163 non-null  int64 \n",
      " 1   geolocation_state            1000163 non-null  object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 15.3+ MB\n"
     ]
    }
   ],
   "source": [
    "geolocation_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be observed that the dataset does not contain any null values.\n",
    "\n",
    "Next, the number of duplicate values in the dataset will be examined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicated row:  981140\n"
     ]
    }
   ],
   "source": [
    "print(\"Duplicated row: \", geolocation_df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geolocation_zip_code_prefix</th>\n",
       "      <th>geolocation_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1046</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1013</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1012</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1037</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1046</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    geolocation_zip_code_prefix geolocation_state\n",
       "2                          1046                SP\n",
       "10                         1013                SP\n",
       "13                         1012                SP\n",
       "14                         1037                SP\n",
       "15                         1046                SP"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geolocation_duplicated = geolocation_df.duplicated()\n",
    "geolocation_df[geolocation_duplicated].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be observed that the rows are truly duplicated. Therefore, the duplicated rows will be removed in the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "geolocation_df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the 'geolocation_state' column will be standardized by removing any leading or trailing whitespace to ensure consistency in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "geolocation_df['geolocation_state'] = geolocation_df['geolocation_state'].apply(lambda x: str(x).strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Category Name Translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next data will also be loaded using the pandas library and stored in the variable category_translation_df, with the first five rows displayed to gain an initial understanding of the structure and contents of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_category_name</th>\n",
       "      <th>product_category_name_english</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>beleza_saude</td>\n",
       "      <td>health_beauty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>informatica_acessorios</td>\n",
       "      <td>computers_accessories</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>automotivo</td>\n",
       "      <td>auto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cama_mesa_banho</td>\n",
       "      <td>bed_bath_table</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>moveis_decoracao</td>\n",
       "      <td>furniture_decor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    product_category_name product_category_name_english\n",
       "0            beleza_saude                 health_beauty\n",
       "1  informatica_acessorios         computers_accessories\n",
       "2              automotivo                          auto\n",
       "3         cama_mesa_banho                bed_bath_table\n",
       "4        moveis_decoracao               furniture_decor"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_translation_url = \"https://raw.githubusercontent.com/aryashidika/Brazilian-Store-Analysis/refs/heads/main/data/raw/product_category_name_translation.csv\"\n",
    "category_translation_df = pd.read_csv(category_translation_url)\n",
    "category_translation_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step will examine the summary of the data using info(), which provides information on missing values and data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 71 entries, 0 to 70\n",
      "Data columns (total 2 columns):\n",
      " #   Column                         Non-Null Count  Dtype \n",
      "---  ------                         --------------  ----- \n",
      " 0   product_category_name          71 non-null     object\n",
      " 1   product_category_name_english  71 non-null     object\n",
      "dtypes: object(2)\n",
      "memory usage: 1.2+ KB\n"
     ]
    }
   ],
   "source": [
    "category_translation_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that there are no columns with null or missing values, and the data types are appropriate.\n",
    "\n",
    "The next line checks for duplicate entries in the customer_id column of the category_translation_df DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicated_rows:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Duplicated_rows: \", category_translation_df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, both the product_category_name and product_category_name_english columns in the category_translation_df DataFrame are standardized by removing any leading or trailing whitespace. This ensures consistency and avoids potential mismatches due to unintended spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_translation_df['product_category_name'] = category_translation_df['product_category_name'].apply(lambda x: str(x).strip())\n",
    "category_translation_df['product_category_name_english'] = category_translation_df['product_category_name_english'].apply(lambda x: str(x).strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load to Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, a connection to the SQLite database is established using the sqlite3.connect() function. The database file is located at the specified path (../database/cleaned_data.db) and the connection is stored in the variable conn for use in subsequent database operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_directory = \"../database/cleaned_data.db\"\n",
    "conn = sqlite3.connect(db_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, several cleaned DataFrames are written to the SQLite database as separate tables using the to_sql() method. Each DataFrame is saved under a specified table name, with if_exists=\"replace\" ensuring that any existing tables with the same name are replaced. The index=False parameter prevents pandas from writing the DataFrame index as a separate column.\n",
    "\n",
    "The following tables are created:\n",
    "- customers\n",
    "- orders\n",
    "- order_items\n",
    "- products\n",
    "- geolocation\n",
    "- cat_translate\n",
    "\n",
    "This process prepares the data for efficient querying and analysis using SQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customers_df.to_sql(\"customers\", conn, if_exists=\"replace\", index=False)\n",
    "orders_df.to_sql(\"orders\", conn, if_exists=\"replace\", index=False)\n",
    "order_items_df.to_sql(\"order_items\", conn, if_exists=\"replace\", index=False)\n",
    "products_df.to_sql(\"products\", conn, if_exists=\"replace\", index=False)\n",
    "geolocation_df.to_sql(\"geolocation\", conn, if_exists=\"replace\", index=False)\n",
    "category_translation_df.to_sql(\"cat_translate\", conn, if_exists=\"replace\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The conn.close() command is used to properly close the connection to the SQLite database. This is a good practice to release resources and ensure that all transactions are finalized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
